{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN using Pytorch for Cancer detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lungenkrebs Datensatz in das System Laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['lung_aca', 'lung_n', 'lung_scc']\n"
     ]
    }
   ],
   "source": [
    "lung_dataset = '/Users/I550949/Desktop/Master Inforamtik/1.Fachsemester/ML/lung_colon_image_set/lung_image_sets'\n",
    "if not os.path.exists(lung_dataset):\n",
    "    raise FileNotFoundError(f\"Dataset path {lung_dataset} does not exist!\")\n",
    "\n",
    "class_names=sorted(os.listdir(lung_dataset))\n",
    "print(f\"Classes found: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilder in Train, Test und Validierungssplits aufteilen\n",
    "\n",
    "Teilt die Bilder in drei Kategorien ein\n",
    "- 80% sind Trainingsdaten\n",
    "- 10% sind Testdaten\n",
    "- 10% sind Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 12000\n",
      "Validation samples: 1500\n",
      "Test samples: 1500\n"
     ]
    }
   ],
   "source": [
    "def prepare_splits(datadir, split_ratios=(0.8, 0.1, 0.1)):\n",
    "    all_data = {cls: [os.path.join(datadir, cls, fname)\n",
    "                      for fname in os.listdir(os.path.join(datadir, cls))]\n",
    "                for cls in class_names}\n",
    "    \n",
    "    splits = {'train': [], 'valid': [], 'test': []}\n",
    "    \n",
    "    for cls, files in all_data.items():\n",
    "        train_files, temp_files = train_test_split(files, test_size=(1 - split_ratios[0]))\n",
    "        val_files, test_files = train_test_split(temp_files, test_size=split_ratios[2] / (split_ratios[1] + split_ratios[2]))\n",
    "        \n",
    "        splits['train'].extend(train_files)\n",
    "        splits['valid'].extend(val_files)\n",
    "        splits['test'].extend(test_files)\n",
    "        \n",
    "    return splits\n",
    "\n",
    "data_splits = prepare_splits(lung_dataset)\n",
    "print(f\"Training samples: {len(data_splits['train'])}\")\n",
    "print(f\"Validation samples: {len(data_splits['valid'])}\")\n",
    "print(f\"Test samples: {len(data_splits['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = [class_names.index(os.path.basename(os.path.dirname(fp))) for fp in file_paths]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])    \n",
    "\n",
    "# Datasets\n",
    "train_dataset = LungDataset(data_splits['train'], transform=transform)\n",
    "val_dataset = LungDataset(data_splits['valid'], transform=transform)\n",
    "test_dataset = LungDataset(data_splits['test'], transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN Klasse mit 6 convolutional Layer, 1 Pooling Layer, 3 batch normalizer und 2 Fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding='same')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding='same')\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding='same')\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "        #print(f\"Shape after conv layers: {x.shape}\")\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad cam with bounding box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Modells\n",
    "\n",
    "Training des Modells auf einem Trainingsdatensatz und Validierung durch einen Validierungsdatensatz über eine bestimmte Anzahl von Epochen. Verwendung von Adam-Optimierer und die Kreuzentropie-Verlustfunktion. Die Funktion verfolgt und speichert die Trainingsverluste, Validierungsverluste und Validierungsgenauigkeit für jede Epoche.\n",
    "\n",
    "#### Ablauf\n",
    "- Initialisiert den Adam-Optimierer und die Kreuzentropie-Verlustfunktion\n",
    "- Verschiebt Modell auf das angegebene Gerät (CPU oder GPU)\n",
    "- Initialisiert Listen zur Speicherung der Verluste und Genauigkeit\n",
    "- **Trainingsschritte pro Epoche**\n",
    "\n",
    "    - Daten auf das Gerät verschieben\n",
    "    - Gradienten zurücksetzen\n",
    "    - Vorwärtsdurchlauf, Parameter aktualieren\n",
    "    - Verlust akkumulieren\n",
    "    - Durchschnittliche Trainingsverluste berechnen\n",
    "\n",
    "- **Validierung pro Epoche**\n",
    "\n",
    "    - Modell in Evaluierungsmodus setzen, verlust und Zähler initialisieren\n",
    "    - Für jede Charge:\n",
    "        - Daten auf Gerät schieben\n",
    "        - Vorwärtsdurchlauf, Verlust berechnen\n",
    "        - Verlust akkumulieren\n",
    "        - Vorhersagen analysieren, Genauigkeit berechnen\n",
    "    - Durchschnittlichen Validierungsverlust und -genauigkeit berechnen und ausgeben\n",
    "    \n",
    "- Gibt die Listen der Trainingsverluste, Validierungsverluste und Validierungsgenauigkeiten zurück\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=2, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "    \n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_losses.append (epoch_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "                \n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader)}, Validation Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.27401521599416934\n",
      "Validation Loss: 0.3024226388135353, Validation Accuracy: 88.06666666666666\n",
      "Epoch 2, Loss: 0.1880643384071688\n",
      "Validation Loss: 0.2509187474249176, Validation Accuracy: 89.53333333333333\n",
      "Training abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = CNN_Model(num_classes=len(class_names))\n",
    "    train_model(model, train_loader, val_loader)\n",
    "\n",
    "    # Testen oder Beispielbild mit Bounding Boxes\n",
    "    print(\"Training abgeschlossen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m         ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[labels[idx]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[predicted[idx]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mvisualize_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m, in \u001b[0;36mvisualize_predictions\u001b[0;34m(model, test_loader, class_names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_predictions\u001b[39m(model, test_loader, class_names):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m      3\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_loader))\n\u001b[1;32m      4\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "def visualize_predictions(model, test_loader, class_names):\n",
    "    #model.eval()\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    images = images.cpu()\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    for idx in range(20): \n",
    "        ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\n",
    "        img = images[idx].permute(1, 2, 0)  \n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])  \n",
    "        img = img.numpy().clip(0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"True: {class_names[labels[idx]]}\\nPred: {class_names[predicted[idx]]}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_predictions(model, test_loader, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_labels, all_preds\n\u001b[0;32m---> 23\u001b[0m all_labels, all_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_model\u001b[39m(model, test_loader):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m      3\u001b[0m     test_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m     test_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    return all_labels, all_preds\n",
    "\n",
    "all_labels, all_preds = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mall_labels\u001b[49m, all_preds, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(class_names)))\n\u001b[1;32m      2\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[1;32m      3\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds, labels=range(len(class_names)))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 18\u001b[0m plot_loss_accuracy(\u001b[43mtrain_losses\u001b[49m, val_losses, val_accuracies)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "#train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "# plotting the loss and accuracy\n",
    "def plot_loss_accuracy(train_losses, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(val_losses, label='Validation loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Validation accuracy')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss_accuracy(train_losses, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# savving the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlung_cancer_model_2.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m(), save_path)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "# savving the model\n",
    "save_path = 'lung_cancer_model_2.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
